                     +-------------------------+
                     | CS 140                  |
                     | PROJECT 4: FILE SYSTEMS |
                     | DESIGN DOCUMENT         |
                     +-------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Ruizhongtai Qi <rqi@stanford.edu>
Zhihao Jia <zhihao@stanford.edu>
Tai Guo <taig@stanford.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

		     INDEXED AND EXTENSIBLE FILES
		     ============================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

>> A2: What is the maximum size of a file supported by your inode
>> structure?  Show your work.

---- SYNCHRONIZATION ----

>> A3: Explain how your code avoids a race if two processes attempt to
>> extend a file at the same time.

>> A4: Suppose processes A and B both have file F open, both
>> positioned at end-of-file.  If A reads and B writes F at the same
>> time, A may read all, part, or none of what B writes.  However, A
>> may not read data other than what B writes, e.g. if B writes
>> nonzero data, A is not allowed to see all zeros.  Explain how your
>> code avoids this race.

>> A5: Explain how your synchronization design provides "fairness".
>> File access is "fair" if readers cannot indefinitely block writers
>> or vice versa.  That is, many processes reading from a file cannot
>> prevent forever another process from writing the file, and many
>> processes writing to a file cannot prevent another process forever
>> from reading the file.

---- RATIONALE ----

>> A6: Is your inode structure a multilevel index?  If so, why did you
>> choose this particular combination of direct, indirect, and doubly
>> indirect blocks?  If not, why did you choose an alternative inode
>> structure, and what advantages and disadvantages does your
>> structure have, compared to a multilevel index?

			    SUBDIRECTORIES
			    ==============

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> B2: Describe your code for traversing a user-specified path.  How
>> do traversals of absolute and relative paths differ?

---- SYNCHRONIZATION ----

>> B4: How do you prevent races on directory entries?  For example,
>> only one of two simultaneous attempts to remove a single file
>> should succeed, as should only one of two simultaneous attempts to
>> create a file with the same name, and so on.

>> B5: Does your implementation allow a directory to be removed if it
>> is open by a process or if it is in use as a process's current
>> working directory?  If so, what happens to that process's future
>> file system operations?  If not, how do you prevent it?

---- RATIONALE ----

>> B6: Explain why you chose to represent the current directory of a
>> process the way you did.

			     BUFFER CACHE
			     ============

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

-- cache.c --

- New defines:
#define BUFFER_CACHE_SIZE 64           /* Number of cache entries. */
#define CACHE_FLUSH_PERIOD 10          /* Flush period in second. */
#define CACHE_FLUSH_PERIOD_TICKS (TIMER_FREQ * CACHE_FLUSH_PERIOD)

- New structs:
/* Cache entry for the file blocks' cache, i.e. buffer_cache. */
struct cache_entry
{
  block_sector_t sector;               /* Sector number of the cached block. */
  block_sector_t new_sector;           /* Sector no of block after eviction. */
  bool accessed;                       /* Whether has been accessed. */
  bool dirty;                          /* Whether has been written. */
  bool evicting;                       /* Entry being evicted. */
  bool flushing;                       /* Entry being flushed. */
  size_t reader;                       /* Number of active readers. */
  size_t writer;                       /* Number of active writers. */
  size_t waiting_reader;               /* Number of waiting readers. */
  size_t waiting_writer;               /* Number of waiting writers. */
  struct lock lock;                    /* Per entry lock. */
  struct condition ready;              /* Per entry condition variable. */
  uint8_t content[BLOCK_SECTOR_SIZE];  /* Block content. */
};

/* Read-ahead task struct. */
struct read_ahead_task
{
  block_sector_t sector;               /* Sector to read ahead. */
  struct list_elem elem;               /* Element for read_ahead_list. */
};

- New static variables:
/* Buffer cache of file blocks. 
 * In default, as many as 64 blocks can be cached. */
static struct cache_entry buffer_cache[BUFFER_CACHE_SIZE];

/* Global buffer cache lock to prevent two threads from evicting 2 entries
 * for the same sector. Concurrency is kept by releasing the lock before IO. */
static struct lock buffer_cache_lock;

/* Clock hand for eviction algorithm. */
static size_t hand;
static struct lock hand_lock;

/* Read-ahead task queue. */
static struct list read_ahead_list;
static struct lock read_ahead_lock;
static struct condition read_ahead_ready;

---- ALGORITHMS ----

>> C2: Describe how your cache replacement algorithm chooses a cache
>> block to evict.

We used basic clock algorithm for cache eviction (in function evict_entry_id).
A global clock hand variable is maintained. Every time we need to evict a cache
entry, we firstly look at the entry with index number of current clock hand.
Each entry access is protected by a monitor (lock and condition variable).

(1) If the entry is being read/written or some thread is waiting to read/write
it or if the entry is being written back to disk (flushing) or bing evicted,
skip the entry by increasing clock hand by one and look at the next entry.
(2) If the entry is recently accessed (accessed flag set), clear the flag and
skip it to next entry.
(3) At this stage, the entry is known as unaccessed and not being read/written 
and not being waited to access and not in flushing/eviction. It is the entry we
will evict. The entry's evicting flag is set. If the entry's dirty flag is set, 
we flush it to disk before returning its index.

>> C3: Describe your implementation of write-behind.

Our design achieves lazy-writing/write-behind. Cached sector is written back to
disk (I/O) only when (1) it is dirty and (2) the cache entry needs to be 
evicted. Each time before a writing disk I/O happens, the entry's flushing flag
is set, so that other thread can be aware not to read or write the sector in
the meantime. During flushing, all locks are released for best concurrency. 
After the disk I/O finishes, the entry's flushing flag is reset.

A background thread (periodic_flush_daemon) is created at cache initialization.
The daemon periodically flushes buffer cache by calling timer_sleep and 
cache_flush. In default, our design flushes the cache every 10 seconds. 
cache_flush is also called in filesys_done().

>> C4: Describe your implementation of read-ahead.

Our buffer cache design maintains a read-ahead task queue. Each time a read-
ahead task is issued (by calling cache_read_ahead), a read_ahead_task is 
created and pushed back to the queue. Also a signal is sent to the daemon 
thread mentioned below. 

Read ahead task is issued in inode_read_at function when there is more block 
to read in the file. Since it does not do any I/O (which will be handled 
asynchronously by the daemon mentioned below), it returns immediately 
and will not block the current thread.

A background thread (read_ahead_daemon) is created at cache init which
runs a while loop to check whether there is task in the queue: if there is,
it pop the task and execute it by making a cache_read call of the to-be-read-
ahead sector. If the queue is empty, it cond_wait on read_ahead_ready cond.

To prevent wasteful read-ahead (read-ahead task executed after the block is 
read into cache), read-ahead task of sector A is canceled when a process calls
cache_read on sector A before the read-ahead task is executed by the daemon.

---- SYNCHRONIZATION ----

>> C5: When one process is actively reading or writing data in a
>> buffer cache block, how are other processes prevented from evicting
>> that block?


increment waiting_reader/writer and reader/writer.
eviction checks WR+WW+R+W>0, if it is true, skip the entry.
every operation on entry is in monitor of entry lock and cond.

>> C6: During the eviction of a block from the cache, how are other
>> processes prevented from attempting to access the block?

setting flushing flag to true.

---- RATIONALE ----

>> C7: Describe a file workload likely to benefit from buffer caching,
>> and workloads likely to benefit from read-ahead and write-behind.

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students in future quarters?

>> Any other comments?

