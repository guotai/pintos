                    +---------------------------+
                    | CS 140                    |
                    | PROJECT 3: VIRTUAL MEMORY |
                    | DESIGN DOCUMENT           |
                    +---------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Ruizhongtai Qi <rqi@stanford.edu>
Zhihao Jia <zhihao@stanford.edu>
Tai Guo <taig@stanford.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.
None.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.
None.

			PAGE TABLE MANAGEMENT
			=====================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

-- In thread.h --
Change struct thread:
struct thread
{
  bool is_user;                       /* Flag to identify whether the 
                                         thread is user process. */
  struct spt spt;                     /* Supplemental page table */
  struct mte *mt;                     /* Mmap table */
  int mt_size;                        /* Mmap table size */
  void *esp;                          /* User esp value at the initial
                                         transition from user to kernel*/
}

New struct mte:
/* Mmap table entry */
struct mte
{
  void *vaddr;                          /* The start addr of this map */
  size_t size;                          /* The mapped page count */
};

-- In page.h --
New struct file_meta:
/* file metadata for each mmap file*/
struct file_meta
{
  struct file *file;            /* pointer to a file structure */
  off_t offset;                 /* offset in the above file */
  size_t read_bytes;            /* total amount of bytes to read */
};

New union struct daddr:
/* union used by supplemental page table
 * entry to find corresponding files */
union daddr
{
  size_t swap_addr;             /* If this page is stored in as a swap page,
                                   swap_add indicates the slot num of the page
                                   in swap table */
  struct file_meta file_meta;   /* If the page is stored in disk as a mmap
                                   file, file_meta data stores necessary
                                   information to regain the page */
};

New struct spt:
/* supplemental page table */
struct spt
{
  struct hash table;            /* hash table to implement supplemental page
                                   table */
  struct lock lock;             /* lock for supplemental page table */
};

New struct spte:
/* supplemental page table entry*/
struct spte
{
  uint32_t *pte;                /* pointer to a page table entry*/
  union daddr daddr;            /* union used to find cooresponding file*/
  struct hash_elem elem;        /* element for hash table */
};

-- pte.h --
New flags for page table entry
#define PTE_FLAGS 0x00000fff    /* Flag bits. */
#define PTE_ADDR  0xfffff000    /* Address bits. */
#define PTE_AVL   0x00000e00    /* Bits available for OS use. */
#define PTE_P 0x1               /* 1=present, 0=not present. */
#define PTE_W 0x2               /* 1=read/write, 0=read-only. */
#define PTE_U 0x4               /* 1=user/kernel, 0=kernel only. */
#define PTE_F 0x8               /* 1=comes from file, 0=in memory */
#define PTE_E 0x10              /* 1=comes from executable, 0=normal */
#define PTE_A 0x20              /* 1=accessed, 0=not acccessed. */
#define PTE_D 0x40              /* 1=dirty, 0=not dirty (PTEs only). */
#define PTE_I 0x80              /* 1=pinned, 0=not pinned. */


---- ALGORITHMS ----

>> A2: In a few paragraphs, describe your code for locating the frame,
>> if any, that contains the data of a given page.

We handle the frame location by considerring the following cases in order.

Case 1: The page table entry (pte) has its present bit (PTE_P) set to 1.
In this case, the page is stored in a current frame. The location look up
is handled by hardware MMU.

Case 2: Stack growth. The page fault caused by stack growth is handled by
a heuristic mechanism. If a page fault occurs and it is recognized as a 
stack growth page fault, we allocate a new zero page from the user pool
and install the page (if there is no new page from the user pool, a frame
eviction happens).

Case 3: Load from file system. In the page fault handler, if the fault page
has PTE_F bit set, then we know this page has a file replica saved in file
system. We handle this case by first looking up supplemental page table (spt),
and get a file metadata entry, which guides us to fetch the page from file
system and save it into a new frame slot. Eviction may happen if we cannot
find free frame slot in frame table.

Case 4: Load from swap. If the above three cases doesn't happen and the fault
page do have a page table entry (pte), we can reach to a conclusion that this
page is saved in a swap slot. Each process has a supplemental page table, 
which is used to find the corresponding swap slot in this case. The user can 
load the page from swap and fill it into a new frame slot (eviction may 
happen in this case).


>> A3: How does your code coordinate accessed and dirty bits between
>> kernel and user virtual addresses that alias a single frame, or
>> alternatively how do you avoid the issue?

Our kernel could avoid the problem by only accessing user data through the
user virtual address, which means every access to user data should hold
an address in user virtual address space.


---- SYNCHRONIZATION ----

>> A4: When two user processes both need a new frame at the same time,
>> how are races avoided?

We design a frame table (ft) which contains lots of frame table entries (fte)
that is one-to-one mapped to frames in user memory pool.

When two processes get new frames from user memory pool at the same time,
the race condictions are avoided by user meory pool lock, since each process
has to get the pool lock before allocate new frames.

When two processes both want to get an existing frame by frame eviction, the
race condictions are avoided by fte lock. For each fte, we design a lock, which
must be acquired before a process can evict this frame.

In other cases, there is no race condition.


---- RATIONALE ----

>> A5: Why did you choose the data structure(s) that you did for
>> representing virtual-to-physical mappings?

In our design, physically, a map can be stored in one of the following places:

Case 1. Frame. Every time when we try to access a vitual memory address, we
have to load the containing page into a frame (which is a memory page) if
a page fault happens.

Case 2. Swap. Swap entries are used to save pages if the user memory pool
is completely occupied.

Case 3. File. Some pages may be evicted into files if it is an unmodified 
executable file or memory mapped file.

Virtual-to-physical mappings for Case 1 is handle by frame table, while
that for Case 2 and Case 3 is handled by supplemental page table.

We design a frame table (ft) which contains lots of frame table entries (fte)
that is one-to-one mapped to frames in user memory pool. We add a lock into
each fte to avoid race conditions. In our design, each fte has its own lock,
and process only has to acquire lock for the particular frame it is operating
on (e.g., evicting that frame). This provides parallism by allowing different
processes evicting different frames in parallel. Processes share the unique
frame table, which is implemented as an array. Since the members in frame table
is decided during kernel boot. Array can provide best performance since there
is no frame inserted into or removed from frame table during user program
execution.

To keep track fo the mappings from virtual to physical, we design supplemental
page table (spt), which contains supplemental page table entries (spte)
representing the location of a page in swap or file system, if the page is not
present. Each process has its own spt. We choose to use hash table to
implement spt, since it can provide O(1) time complexity for insertion,
deletion, and lookup. 


		       PAGING TO AND FROM DISK
		       =======================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

-- In frame.h --
New enum type:
/* flages for each frame entry */
enum frame_flags
{
    FRM_ASSERT = 0x1,           /* Panic on failure. */
    FRM_ZERO = 0x2,             /* Zero page contents. */
    FRM_USER = 0x4,             /* User page. */
    FRM_MMAP = 0x8              /* Page used for mmap. */
};

/* Frame table entry */
struct fte
{
  struct thread *thread;        /* Thread that owns this frame table entry. */
  uint32_t *pte;                /* The beginning virtual address that cooresponds
                                   to this frame table entry. */
  struct lock lock;             /* Per entry lock. */
};

/* Frame table */
struct frame_table
{
  size_t size;                  /* Total number of frames in this frame table */
  struct fte *frames;           /* Frames in the table */
  size_t clock_hand;            /* Clock hand for eviciton algorithm. */
  struct lock clock_lock;       /* Lock for clock_hand. */
};

struct frame_table frame_table; /* Global table used to check user memory. */

-- In swap.h --
New struct swap_table:
/* Swap talbe used to track used disk space. */
struct swap_table
{
  struct block *swap_block;     /* Swap block for paging. */
  struct bitmap *used_map;      /* Bitmap for free swap pages. */
  struct lock block_lock;       /* Lock to protect swap_block. */
  struct lock bitmap_lock;      /* Lock to protect used_map. */
};

struct swap_table swap_table;  /* Global table tracking swap frames in swap block. */

---- ALGORITHMS ----

>> B2: When a frame is required but none is free, some frame must be
>> evicted.  Describe your code for choosing a frame to evict.

We used clock algorithm for frame eviction. Each time the system need to 
evict a page, it iterate through the frames in frame_table starting from 
where the clock_hand was last time. For each frame, the algorithm go through 
the following checks until find an evictable frame.

(1) If the frame is pinned or the frame's lock is held by others, go on.
(2) If the frame/page is accessed recently (pte's PTE_A is set), reset the 
page's access bit and go on to next frame.
(3) If the frame is not accessed recently but dirty, write page back to file
if it's mmapped or write it to swap slot if it from exec. file or non-file, 
then set spte accordingly, reset dirty bit and go on to next frame.
(4) If the frame is neither accessed recently nor dirty, it's evictable. We
need to write it to a swap slot if the page is from non-file and set spte
accordingly. Now, a frame has been successfully evicted and free to use.

>> B3: When a process P obtains a frame that was previously used by a
>> process Q, how do you adjust the page table (and any other data
>> structures) to reflect the frame Q no longer has?

In our design, each physical page in user pool is represented by a frame
table entry. Each frame table entry records the owner thread of the physical 
frame and the page table entry corresponding to it. Status of a page is 
stored in the last 12 bits (FLAGS) of its page table entry, i.e. whether it 
is a file page, an executable file page or a pinned page etc. From a thread's 
supplemental page table (a hash table) and its page's pte, we can find the 
page's spte, which stores the eviction related information such as the file 
source or swap slot number etc. 

                                SPTE, t->spt[index]
                               -----------------------
                        SPT - | uint32_t *pte         |
         FTE          /       | struct daddr daddr  - - -> swap slot or file
   ----------------- /        | struct hash_elem elem |
  | struct thread *t |         ---------------------- \
  | uint32_t *pte    |                                 | (hash)
   --------------- \-                PTE              /
                    \   -----------------------------
                     \ | 20bit PhyAddr | 12bit FLAGS |
                        -----------------------------

Firstly, process Q's corresponding virtual page is set as unpresent 
(i.e. PTE_P bit is 0) and the page is written back to file or swap slot if 
necessary. The address of the page in file or swap disk is recorded in 
the page's corresponding spte. Thus, next time the process Q's page is 
accessed a page fault will be trigured.

Secondly, the frame entry is modified to point to process P's page's PTE and
also owner thread becomes thread P.

>> B4: Explain your heuristic for deciding whether a page fault for an
>> invalid virtual address should cause the stack to be extended into
>> the page that faulted.

In struct thread, we add a new field (void *esp) to keep track of the
esp register at the initial transition when a process swaps from user
mode to kernel mode. In syscall handler, we set thread->esp to be the
value esp register for user stack. By this new field, we can always
get the value of esp register for user stack, whether we are in user
mode or kernel mode.

Our heuristic algorithm decides whether a page fault should cause
stack growth be checking the following conditions:
( In the following code, fault_addr is the invalide virtual address,
while esp is the esp register for user stack )

1. (fault_addr == esp - 4)          /* case for PUSH op */
   or (fault_addr == esp - 32)      /* case for PUSHA op */
   or (fault_addr >= esp)           /* case for MOV and SUB op*/

2. fault_addr >= PHYS_BASE - 8MB    /* stack size cannot extends 8MB*/

3. page table entry (pte) is null   /* stack growth case */
   or pte hasn't been loaded        /* laze load case */
   
If the above three criteria are satisfied, the heuristic algorithm 
considers this page fault as a case for stack extension.

---- SYNCHRONIZATION ----

>> B5: Explain the basics of your VM synchronization design.  In
>> particular, explain how it prevents deadlock.  (Refer to the
>> textbook for an explanation of the necessary conditions for
>> deadlock.)

The synchronization primitives we used are as following:
(1) Per thread supplemental page table lock. 
  Each thread has a suppl. page table and each SPT has a lock to realize 
  critical section for spte, especially to prevent non-atomic modificatons of 
  spte during evictions.
(2) Per entry frame table entry lock. 
  Each frame entry has a per-entry lock to prevent two threads from evicting 
  the same frame. Each time a thread examines a evicting candidate frame, the 
  frame is guarded by its FTE's lock.
(3) Global file system lock. 
  Each operation on file system, such as file open, file read, write or seek, 
  is protected by a single filesys_lock.
(4) Global pin lock. 
  Since PTE can be accessed in more than one place and by more than one thread, 
  a pin lock is used whenever we need to set or reset a page's PTE. It is also 
  used together with the pin cond.
(5) Global pin condition variable. 
  A page is pinned to prevent page faults occurances while a device driver 
  accesses a user bufferer passed to file_read, file_write etc. Once the 
  operation on the page is finished, the page is unpinned intermediately. 
  A conditional variable is used to avoid busy waiting for a pte pinning 
  operation.
(6) Swap table bitmap and block locks. 
  Two locks are used only inside swap.c methods to realize atomic operation 
  on the swap bitmap and swap block.
(7) Frame table clock_hand lock. 
  frame_table has a lock used solely for atmoic look up and increment of 
  clock_hand.

We prevent deadlock by eliminate circularity of requests and ownership. 
We set an fixed ordering of all lock acquires (lock releases are in inverse 
order). Lock (1) is always acquired first, (2) afterwards and (3) at last.
Locks (3)~(7) are lowest level locks, i.e. there is no lock acquires when a
thread holds any lock of (3)~(7).

>> B6: A page fault in process P can cause another process Q's frame
>> to be evicted.  How do you ensure that Q cannot access or modify
>> the page during the eviction process?  How do you avoid a race
>> between P evicting Q's frame and Q faulting the page back in?

>> B7: Suppose a page fault in process P causes a page to be read from
>> the file system or swap.  How do you ensure that a second process Q
>> cannot interfere by e.g. attempting to evict the frame while it is
>> still being read in?

When process P is loading a page from file or swap during a page fault,
the PTE of the to-be-loaded page is pinned, i.e. PTE_I set to 1. Thus,
when process Q examines the corresponding frame to process P's page, it
will skip the frame since it is pinned.

Only after process P finishes the page loading, is the page unpinned and
the corresponding frame can be candidates to eviction.

>> B8: Explain how you handle access to paged-out pages that occur
>> during system calls.  Do you use page faults to bring in pages (as
>> in user programs), or do you have a mechanism for "locking" frames
>> into physical memory, or do you use some other design?  How do you
>> gracefully handle attempted accesses to invalid virtual addresses?

We check user provided addresses before accessing them. If the user page is 
valid and paged out, the page will be loaded from file or swap; otherwise, 
the user thread will exit with -1. The check is realized by examing the user 
address (whether it is NULL pointer or in kernel memory), corresponding
page's PTE entry flags and its supplemental page entry if there is any.
Actually, in check_user_memory, if we find the page corresponding to user 
provided address is not NULL and in user memory, a simulated page fault is 
triguered by calling _page_fault, which will grow the stack, load the page 
from file or swap if necessary.

As to file system calls such as read and write, the pages are also pinned if
they are valid. Therefore, those pages cannot be evicted during the system call
which prevents deadlocks - system call holds the global file system lock while
page fault happens in system call memory access and require file system lock to
read in page file.

---- RATIONALE ----

>> B9: A single lock for the whole VM system would make
>> synchronization easy, but limit parallelism.  On the other hand,
>> using many locks complicates synchronization and raises the
>> possibility for deadlock but allows for high parallelism.  Explain
>> where your design falls along this continuum and why you chose to
>> design it this way.

We carefully choose sychronization primitives to achieve a sweet point of
complexities and high parallelism/performance. In our design, while one
page fault requires I/O, in the meantime processes that do not fault and 
other page faults that do not require I/O can continue to execute. Also,
our system supports one thread paging out a frame while the other thread
reads in a page into another frame. 

For different data structures we use lock of various levels of fineness, from
global file system lock to per entry frame table lock. More details of our 
choice and design of synchronizations are as below.

(1) Frame Table.
We initialize a global frame table as an fixed size array. Each entry of the 
frame table has a lock. The per entry lock allows high parallelism and by 
keeping a well defined order of locks we can successfully avoid deadlocks. When
one thread is evicting a frame, it acquired and holds the frame entry lock so 
that other threads can continue withouth intefering it from eviction.
(2) Supplemental Page Table.
Since we realized SPTs as hash tables, which are based on list and hash 
functions. Operations on hash tables will modify the structure of the whole
table so that we assign a single lock for each table.
(3) File System Lock.
We used a global file system lock due to the limit of current file system. Any
file system operation is protected by the global filesys_lock. Since we need to 
access a single file system, we have to have a global lock for it.


			 MEMORY MAPPED FILES
			 ===================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

--thread.h--
New struct:
/* Mmap table entry */
struct mte
{
  void *vaddr;                          /* The start addr of this map */
  size_t size;                          /* The mapped page count */
};

New member:
struct thread
{
  struct mte *mt;                     /* Mmap table */
  int mt_size;                        /* Mmap table size */
}

---- ALGORITHMS ----

>> C2: Describe how memory mapped files integrate into your virtual
>> memory subsystem.  Explain how the page fault and eviction
>> processes differ between swap pages and other pages.

In the page table entry, if a page is mapped page, the pte will have the PTE_F
bit set. This bit means that this page comes from a file. If the PTE_E bit is
not set, which means this page does not come from executable file, and the
PTE_F bit is set, then the system know this page is a mapped page. During page
fault and eviction, the system can access the page table entry and check these
bits to know what kind the page is.

To locate the mmap id, we add a mmap table "mt" in the thread struct. So this
table is per thread. The entry of this table contains the vaddr thas is passed
to mmap function by the user, and a size which is the size of the mapped file.
The mmap table is an array with entries of struct mte, and the array can
dynamically extend its size. Since the mmap table is very similar to a file
descriptor table, so we actually reuse most of the code of the file descriptor
table. When adding new entry, the table will do a first fit and return the
entry index as the mmap id, and if there is no enough space, the table will
apply a double size of space and copy everything to the new space. Since
pintos does not have a good malloc (current malloc just assign a whole page),
our design will have better memory usage, while still maintain the amortized
time complexity O(1).

Mmap reuses the code of load_segment which is previously used to load
executable file. The mmap function does some basic check, reopen the file,
call a load_segment and then create the mmap table entry. Actually, the only
difference between a mmap and loading executable is that loading executable
will set the PTE_E bit in pte while mmap does not set that bit. So mmap
will also create the relevant supplemental page table entry which stores the
file, offset and readbytes. Each mapped page will have an spte. The read_bytes
is used to record how many bytes should be read from file, and how many bytes
should be set to 0.

Munmap use the map id to find the mte and get the vaddr and size. Then we can
get all the pte's from vaddr to vaddr+size, and from pte we can get the spte.
From spte, we can get the file pointer. This is why we do not store file
pointer in mte. Now we can loop from vaddr to vaddr+size, if the pte has PTE_P
bit set and PTE_D bit set, then we write this page back to file and free that
page. Then we delete all the relevant spte and set the pte to 0. Then delete
mte.

The page fault handler will check the PTE_F bit, if set then it load that page
from file, using the information in the relevant spte. In eviction, it will
write the page back to file if PTE_D is set. Notice that the spte's relevant
to the mmap is only deleted in munmap.

>> C3: Explain how you determine whether a new file mapping overlaps
>> any existing segment.

In the system, a thread's page table entry changes from zero to non-zero with
some bits set in its flag, and only changes from non-zero to zero in munmap.
So we can just check whether the page table entry is 0 to determin whether
this virtual page is already be reserved for other use, like stack, code or
other mmaps.

---- RATIONALE ----

>> C4: Mappings created with "mmap" have similar semantics to those of
>> data demand-paged from executables, except that "mmap" mappings are
>> written back to their original files, not to swap.  This implies
>> that much of their implementation can be shared.  Explain why your
>> implementation either does or does not share much of the code for
>> the two situations.

The mmap is very similar to loading executable file, so we reuse load_segment
in mmap. The only difference is that in mmap, we do not set PTE_E bit.

In munmap, since there is no relevant in the process of executable file, this
part is new implemented.

In page fault, once the PTE_F bit is set, this page should come from a file,
either executable or mapped file. And the process is exactly same, so we only
have one function called load_from_file to deal with this. In this part the
code is shared between executable and mapped file.

In eviction, the mapped file and executable are different. The mapped page
should be write back to file when dirty while the executable page should be
write to swap. So this part does not share much code. And once an executable
page goes to swap, its pte will reset the PTE_F and PTE_E bits, because this
page will never go back to executable file and will never come from executable
again. This page will be processed just like a stack page. Next time it will
call load_from_swap instead of load_from_file when page fault. But a mapped
page's pte will always have the PTE_F bit set until unmapped. So that page
always goes to file when evict and always comes from file when page fault.

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?

